import os
import json
import openai
import time
from tqdm import tqdm
from openai import OpenAI
from argparse import ArgumentParser
from eval_tool.rough_compute import compute_standard_rough
from eval_tool.bleu_compute import calculate_bleu_scores
from eval_tool.codebleu_compute import codebleu_compute


# å¯¼å…¥å¿…è¦çš„åº“
# os: æ–‡ä»¶è·¯å¾„æ“ä½œ
# json: JSONæ•°æ®å¤„ç†
# time: æ—¶é—´ç›¸å…³æ“ä½œ
# tqdm: è¿›åº¦æ¡æ˜¾ç¤º
# openai: OpenAI APIæ¥å£
# argparse: å‘½ä»¤è¡Œå‚æ•°è§£æ

def parser_args():
    # å®šä¹‰å‘½ä»¤è¡Œå‚æ•°è§£æå‡½æ•°
    parser = ArgumentParser()
    parser.add_argument("--task", type=str, required=True)  # ä»»åŠ¡ç±»å‹ï¼ˆentity/relationï¼‰
    parser.add_argument("--train_dir", type=str, required=True)  # è®­ç»ƒæ•°æ®è·¯å¾„
    parser.add_argument("--test_dir", type=str, required=True)  # æµ‹è¯•æ•°æ®è·¯å¾„
    parser.add_argument("--shot_dir", type=str, required=True)  # ç¤ºä¾‹æ•°æ®è·¯å¾„
    parser.add_argument("--shot_num", type=int, required=True)  # ç¤ºä¾‹æ•°é‡
    parser.add_argument("--prompt_dir", type=str, required=True)  # æç¤ºæ¨¡æ¿è·¯å¾„
    parser.add_argument("--model", type=str, required=True)  # ä½¿ç”¨çš„æ¨¡å‹åç§°
    parser.add_argument("--moda", type=str, default='greedy')  # ç”Ÿæˆæ¨¡å¼ï¼ˆé»˜è®¤è´ªå¿ƒï¼‰
    parser.add_argument("--output_dir", type=str, required=True)  # è¾“å‡ºè·¯å¾„
    return parser.parse_args()

def read_data(args):
    with open(args.train_dir, 'r', encoding='utf-8') as train_file:
        train_data = json.load(train_file)  # åŠ è½½è®­ç»ƒæ•°æ®
    with open(args.test_dir, 'r', encoding='utf-8') as test_file:
        test_data = json.load(test_file)  # åŠ è½½æµ‹è¯•æ•°æ®
    with open(args.shot_dir, 'r', encoding='utf-8') as shot_file:
        shot_data = json.load(shot_file)  # åŠ è½½ç¤ºä¾‹æ˜ å°„æ•°æ®
    with open(args.prompt_dir, 'r', encoding='utf-8') as prompt_file:
        prompt_templeate = prompt_file.read()  # åŠ è½½æç¤ºæ¨¡æ¿
    return train_data["train"], test_data["test"], shot_data["examples"], prompt_templeate


def get_completion(args, prompt, idx):
    client = OpenAI(
        api_key="sk-sR8RiK6YYrtk8Rss1b29047069804d108211285c7a25356c",  # å¡«å†™ä¸Šapi-key
        base_url="https://api.yesapikey.com/v1"
    )
    client.base_url = "https://api.yesapikey.com/v1"
    max_retries = 10
    retry_delay = 0.5

    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=args.model,
                temperature=0
            )
            return response.choices[0].message.content
        except openai.OpenAIError as e:
            print(f"ID: {idx} Attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
                retry_delay *= 2  # æŒ‡æ•°é€€é¿ç­–ç•¥
            else:
                raise


def get_ner_shot_prompt(i, train_data, shot_data, shot_num):
    # æ„å»ºNERä»»åŠ¡çš„ç¤ºä¾‹æç¤º
    prompt = "\n## Examples\n"
    few_shots = shot_data[i]["id"][:shot_num]  # è·å–å½“å‰æµ‹è¯•æ ·æœ¬å¯¹åº”çš„ç¤ºä¾‹IDåˆ—è¡¨
    for shot_id in few_shots:
        shot_input = train_data[shot_id]["text"]  # ç¤ºä¾‹è¾“å…¥æ–‡æœ¬
        shot_answer = train_data[shot_id]["entity"]  # ç¤ºä¾‹å®ä½“æ ‡æ³¨ç»“æœ
        prompt += f"Input:{shot_input}\n"
        prompt += f"Answer:{shot_answer}\n"
    return prompt


def get_ner_prompt(args):
    # ç”ŸæˆNERä»»åŠ¡çš„å®Œæ•´æç¤ºåˆ—è¡¨
    train_data, test_data, shot_data, prompt_templeate = read_data(args)
    prompt_list = []
    if args.shot_num == 0:
        # é›¶æ ·æœ¬æƒ…å†µ
        for test_item in test_data:
            input_req = test_item["text"]
            prompt = prompt_templeate.format(examples="", input_req=input_req)
            prompt_list.append(prompt)
    else:
        # å°‘æ ·æœ¬æƒ…å†µ
        for i, test_item in enumerate(test_data):
            input_req = test_item["text"]
            shot_prompt = get_ner_shot_prompt(i, train_data, shot_data, args.shot_num)
            prompt = prompt_templeate.format(examples=shot_prompt, input_req=input_req)
            prompt_list.append(prompt)
    return prompt_list


def get_rel_shot_prompt(i, train_data, shot_data, shot_num):
    # æ„å»ºRELä»»åŠ¡çš„ç¤ºä¾‹æç¤º
    prompt = "\n## Examples\n"
    # few_shots = shot_data[i][:shot_num]
    for shot_id in (0, shot_num):
        shot_input = train_data[shot_id]["text"]
        # shot_entity = train_data[shot_id]["entity"]  # ç¤ºä¾‹å®ä½“æ ‡æ³¨
        shot_entity = "å¾…å¡«å……"

        shot_answer = train_data[shot_id]["label"]  # ç¤ºä¾‹å…³ç³»æ ‡æ³¨
        prompt += f"x:\n{shot_input}\n"
        prompt += f"G(x):\n{shot_entity}\n"
        prompt += f"y:\n{shot_answer}\n"
        prompt += "\n"
    return prompt


def get_rel_prompt(args, testnum = 1):
    # ç”ŸæˆRELä»»åŠ¡çš„å®Œæ•´æç¤ºåˆ—è¡¨
    train_data, test_data, shot_data, prompt_templeate = read_data(args)
    content_str = construct_pre_prompt()
    prompt_list = []
    train_lable = []
    if args.shot_num == 0:
        # é›¶æ ·æœ¬æƒ…å†µ
        for test_item in test_data:
            input_req = test_item["text"]
            entities = test_item["label"]
            prompt = prompt_templeate.format(examples="", input_req=input_req, entity_list=entities)
            prompt_list.append(prompt)
    else:
        # å°‘æ ·æœ¬æƒ…å†µ
        for i, test_item in enumerate(test_data):
            if i >= testnum:
                break
            input_req = test_item["text"]
            # entities = test_item["entities"]
            shot_prompt = get_rel_shot_prompt(i, train_data, shot_data, args.shot_num)
            # print(f"Prompt template: {prompt_templeate}")
            # print(f"Examples: {shot_prompt}")
            # print(f"Input request: {input_req}")
            # print(f"Entity list: ")
            prompt = prompt_templeate.format(pre_content = content_str, examples = shot_prompt, input_x = input_req + "\n", ans_y = "")
            print(f"âœ…Single prompt example:\n{prompt}")
            prompt_list.append(prompt)
            train_lable.append(test_item["label"])
    return prompt_list, train_lable


def gpt_inference(args):
    # ä¸»æ¨ç†å‡½æ•°
    prompt_list, dist_label= get_rel_prompt(args)
    predict_list = []
    idx = -1
    for prompt in tqdm(prompt_list, desc='generate answer'):
        idx += 1
        predict = get_completion(args, prompt, idx)  # è·å–æ¨¡å‹é¢„æµ‹ç»“æœ
        print(f"\nğŸ“GPT predicted answer :\n{predict}")
        print(f"\nğŸ“„original_answer:\n{dist_label[idx]}")
        predict_dict = {"predict": predict}
        rouge1_f1,rouge2_f1,rougeL_f1 = compute_standard_rough(predict, dist_label[idx])
        bleu_score, bleu_1gram, bleu_2gram = calculate_bleu_scores(dist_label[idx], predict)
        codebleu_res = codebleu_compute(dist_label[idx], predict)
        # æ‰“å° ROUGE åˆ†æ•°
        print("ROUGE åˆ†æ•°:")
        print(f"{'ROUGE-1 F1:':<8} {rouge1_f1:.4f}")
        print(f"{'ROUGE-2 F1:':<8} {rouge2_f1:.4f}")
        print(f"{'ROUGE-L F1:':<8} {rougeL_f1:.4f}")
        print()
        # æ‰“å° BLEU åˆ†æ•°
        print("BLEU åˆ†æ•°:")
        print(f"{'BLEU:':<8} {bleu_score:.4f}")
        print(f"{'1-gram BLEU:':<8} {bleu_1gram:.4f}")
        print(f"{'2-gram BLEU:':<8} {bleu_2gram:.4f}")
        print()
        print("CODEBLEU ç»“æœ:")
        formatted_dict = json.dumps(codebleu_res, indent=4)
        print(f"{'CODEBLEU:':<8} {formatted_dict}")
        predict_list.append(predict_dict)
        time.sleep(0.5)  # æ·»åŠ å»¶è¿Ÿé˜²æ­¢APIè°ƒç”¨è¶…é™

    # æ„å»ºè¾“å‡ºè·¯å¾„
    output_dir = os.path.join(args.output_dir, f"{args.task}/{args.model}")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    output_dir = os.path.join(output_dir, "fold_0")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    output_path = os.path.join(output_dir, f"{args.shot_num}.json")

    # ä¿å­˜ç»“æœ
    json_data = json.dumps(predict_list, ensure_ascii=False, indent=2)
    with open(output_path, 'w', encoding='utf-8') as output_file:
        output_file.write(json_data)

def construct_pre_prompt():
    prompt = "You are an expert on Domain Specific Language Generation, and you need to write formal requirements with a domain-specific language for the given natural language requirements. First, you should write a grammar that contains all the necessary BNF rules. Then, you should write formal requirements that conform to your predicted rules."
    with open("source/rules.txt", "r", encoding="utf-8") as file:
        file_content = file.read()
    return prompt + "\n" + "G(x):" + "\n" + file_content


if __name__ == "__main__":
    args = parser_args()  # è§£æå‘½ä»¤è¡Œå‚æ•°
    # print(args.shot_num)
    # print(args.model)
    gpt_inference(args)  # æ‰§è¡Œæ¨ç†ä»»åŠ¡